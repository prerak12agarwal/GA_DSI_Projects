{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the problem you are finding answers for from the data given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV files using relative filepaths\n",
    "\n",
    "sat17 = pd.read_csv(\"../data/sat_2017.csv\")\n",
    "act17 = pd.read_csv(\"../data/act_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing a few lines of each dataframe to ensure that it was read properly.\n",
    "\n",
    "sat17.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>65%</td>\n",
       "      <td>561</td>\n",
       "      <td>541</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>64%</td>\n",
       "      <td>541</td>\n",
       "      <td>534</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14%</td>\n",
       "      <td>558</td>\n",
       "      <td>528</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3%</td>\n",
       "      <td>642</td>\n",
       "      <td>649</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3%</td>\n",
       "      <td>626</td>\n",
       "      <td>604</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "46       Virginia           65%                                 561   541   \n",
       "47     Washington           64%                                 541   534   \n",
       "48  West Virginia           14%                                 558   528   \n",
       "49      Wisconsin            3%                                 642   649   \n",
       "50        Wyoming            3%                                 626   604   \n",
       "\n",
       "    Total  \n",
       "46   1102  \n",
       "47   1075  \n",
       "48   1086  \n",
       "49   1291  \n",
       "50   1230  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat17.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows in the dataframe.\n",
    "\n",
    "len(sat17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of values in the 'State' column.\n",
    "\n",
    "len(sat17['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "       'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "       'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in the 'State' column.\n",
    "\n",
    "sat17['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29%</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29%</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69%</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29%     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29%     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69%     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100%     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100%     19.4  19.8     20.8     20.6     20.2x"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows in the dataframe.\n",
    "\n",
    "len(act17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of values in the 'State' column.\n",
    "\n",
    "len(act17['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['National', 'Alabama', 'Alaska', 'Arizona', 'Arkansas',\n",
       "       'California', 'Colorado', 'Connecticut', 'Delaware',\n",
       "       'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
       "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
       "       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in the 'State' column.\n",
    "\n",
    "act17['State'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAT 2017:** According to the [source](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/), this dataset *(imported here as 'sat17')* provides a breakdown of the 2017 SAT participation rates *(column 'Participation')*, average scores for EBRW and Math sections *(columns 'Evidence-Based Reading and Writing' and 'Math', respectively)* and the average aggregate scores *(column 'Total')* for all 50 states and 1 federal district (District of Columbia) of the USA *(column 'State', arranged alphabetically)*.\n",
    "\n",
    "The values in the 'State' column are *strings*. The numerical values of the scores in the dataset do not carry any decimal places, and so should be expected to be *integers*. The values in the 'Participation' column carry a numerical value followed by a % symbol. So, these should be expected to be *strings* which would need to be converted to *floats*.\n",
    "\n",
    "**ACT 2017:** Similar to the above, according to the [source](https://www.act.org/content/dam/act/unsecured/documents/cccr2017/ACT_2017-Average_Scores_by_State.pdf), this dataset *(imported here as 'act17')* provides a breakdown of the 2017 ACT participation rates *(column 'Participation')*, average scores for English, Math, Reading and Science sections *(columns 'English', 'Math', 'Reading' and 'Science', respectively)* and the average composite scores *(column 'Composite')* for all 50 states and 1 federal district (District of Columbia) of the USA *(column 'State', arranged alphabetically)*. This dataset also contains one additional row of data for the National participation rate and average section & composite scores.\n",
    "\n",
    "The values in the 'State' column are *strings*. The numerical values of the scores in the dataset carry decimal places, and so should be expected to be *floats*. The values in the 'Participation' column carry a numerical value followed by a % symbol. So, these should be expected to be *strings* which would need to be converted to *floats*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 0\n",
       "Participation                         0\n",
       "Evidence-Based Reading and Writing    0\n",
       "Math                                  0\n",
       "Total                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any empty values in SAT 2017 dataset.\n",
    "\n",
    "sat17.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State            0\n",
       "Participation    0\n",
       "English          0\n",
       "Math             0\n",
       "Reading          0\n",
       "Science          0\n",
       "Composite        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any empty values in ACT 2017 dataset.\n",
    "\n",
    "act17.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Yes, the data is complete as there are no empty values in the two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** *The answers in this section are ONLY based on a quick visual inspection of the CSV files. This method may be usable here because the datasets are relatively small in size (only 5-7 columns, ~51 rows).*\n",
    "\n",
    "For the **SAT**, according to [this page](https://blog.prepscholar.com/how-is-the-sat-scored-scoring-charts), each of the **2 sections** have a 'scaled score' **range of 200 - 800 (inclusive)**. The total score is calculated by adding the 2 sections' scores, thus giving a possible **total score range of 400 - 1600**.\n",
    "\n",
    "A quick visual inspection of the sat_2017 CSV file indicates that one of the values in the dataset is outside the above given ranges. This will have to be corrected, and all other values will also have to be checked using code, to ensure that they are within the correct ranges (which may have been missed during the visual inspection).\n",
    "\n",
    "For the **ACT**, according to [this page](https://blog.prepscholar.com/how-is-the-act-scored), each of the **4 sections** have a 'scaled score' **range of 1 - 36 (inclusive)**. The composite score is calculated by averaging the 4 sections' scores, thus giving a possible **composite score range of 1 - 36**.\n",
    "\n",
    "A quick visual inspection of the act_2017 CSV file indicates that one of the values in the dataset (in column 'Composite') has an incorrect 'x' attached to the numerical value, thus changing the data type of the entire column to *object*. This will have to be corrected, and all other values will also have to be checked using code, to ensure that they are within the correct ranges and of the correct data types (which may have been missed during the visual inspection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      "State            52 non-null object\n",
      "Participation    52 non-null object\n",
      "English          52 non-null float64\n",
      "Math             52 non-null float64\n",
      "Reading          52 non-null float64\n",
      "Science          52 non-null float64\n",
      "Composite        52 non-null object\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset info to verify data types of the columns and any missing values.\n",
    "\n",
    "act17.info()\n",
    "\n",
    "# Column 'Composite' has incorrect data type 'object' when it should be 'float'.\n",
    "# This is because of the incorrect 'x' attached to one of the numerical values\n",
    "# identified during the visual inspection above.\n",
    "\n",
    "# No missing values are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      "State                                 51 non-null object\n",
      "Participation                         51 non-null object\n",
      "Evidence-Based Reading and Writing    51 non-null int64\n",
      "Math                                  51 non-null int64\n",
      "Total                                 51 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset info to verify data types of the columns and any missing values.\n",
    "\n",
    "sat17.info()\n",
    "\n",
    "# All numerical columns in this dataset have the correct data type int.\n",
    "# No missing values are present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>10%</td>\n",
       "      <td>482</td>\n",
       "      <td>52</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>96%</td>\n",
       "      <td>644</td>\n",
       "      <td>651</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "min  Alabama           10%                                 482    52    950\n",
       "max  Wyoming           96%                                 644   651   1295"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking min and max values in the SAT 2017 dataset columns to ensure they are within the correct ranges.\n",
    "\n",
    "# Correct ranges as stated above in section 4b.\n",
    "# EBRW and Math sections' scores: 200 - 800 (inclusive)\n",
    "# Total score: 400 - 1600\n",
    "\n",
    "sat17.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>69%</td>\n",
       "      <td>536</td>\n",
       "      <td>52</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "20  Maryland           69%                                 536    52   1060"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Above table shows min value in Math column 52 < 200.\n",
    "# All other min & max numerical values are within the correct ranges.\n",
    "\n",
    "# Identifying the rows with Math score < 200.\n",
    "\n",
    "sat17.loc[sat17['Math']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-referencing with the source, correct value for Math score for MAryland is 524.\n",
    "\n",
    "# Replacing 52 in the above row with 524.\n",
    "\n",
    "sat17.loc[sat17['State']==\"Maryland\", 'Math'] = 524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>69%</td>\n",
       "      <td>536</td>\n",
       "      <td>524</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "20  Maryland           69%                                 536   524   1060"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking again to ensure the value is correctly replaced.\n",
    "\n",
    "sat17.loc[sat17['State']==\"Maryland\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>60%</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>98%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State Participation  English  Math  Reading  Science Composite\n",
       "min  Alabama           60%     16.3  18.0     18.1      2.3      17.8\n",
       "max  Wyoming           98%     25.5  25.3     26.0     24.9      25.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking min and max values in the ACT 2017 dataset columns to ensure they are within the correct ranges.\n",
    "\n",
    "# Correct ranges as stated above in section 4b.\n",
    "# English, Math, Reading and Science sections' scores: 1 - 36 (inclusive)\n",
    "# Composite score: 1 - 36 (may not be correct, will have to be checked again after chainging column to float data type)\n",
    "\n",
    "act17.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data types of the columns.\n",
    "\n",
    "sat17.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data types of the columns.\n",
    "\n",
    "act17.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** As explained in section 4b. above, the 'Composite' column in ACT 2017 dataset has an incorrect data type *object* (because of an incorrect 'x' attached to one of the numerical values). This needs to be converted to *float*.\n",
    "\n",
    "Also, as explained in section 3. above, the 'Participation' columns in both datasets are of type *object* because of the presence of a % symbol after the numerical values. These should be converted to type *float* as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SAT 2017 dataset\n",
    "# Converting 'Participation' column from type object to type float by removing the % symbol after all numerical values.\n",
    "# lambda function replaces the '%' in the strings with '' and then converts them to float.\n",
    "# All float values are divided by 100 because they are percentages.\n",
    "# .map funtion maps the lambda function to all values in 'Participation' column.\n",
    "\n",
    "sat17['Participation'] = sat17[\"Participation\"].map(lambda pct : float(pct.replace(\"%\", \"\"))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data type of the column to ensure it is now of type float.\n",
    "\n",
    "sat17['Participation'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating above steps for ACT 2017 dataset.\n",
    "\n",
    "act17['Participation'] = act17[\"Participation\"].map(lambda pct : float(pct.replace(\"%\", \"\"))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data type of the column to ensure it is now of type float.\n",
    "\n",
    "act17['Participation'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['21.0', '19.2', '19.8', '19.7', '19.4', '22.8', '20.8', '25.2',\n",
       "       '24.1', '24.2', '21.4', '19.0', '22.3', '22.6', '21.9', '21.7',\n",
       "       '20.0', '19.5', '24.3', '23.6', '25.4', '21.5', '18.6', '20.4',\n",
       "       '20.3', '17.8', '25.5', '23.9', '19.1', '22.0', '21.8', '23.7',\n",
       "       '24.0', '18.7', '20.7', '23.8', '20.5', '20.2x'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ACT 2017 dataset\n",
    "# Checking all unique values of 'Composite' column to look for any abnormalities.\n",
    "\n",
    "act17['Composite'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  Participation  English  Math  Reading  Science Composite\n",
       "51  Wyoming            1.0     19.4  19.8     20.8     20.6     20.2x"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out the row with the incorrect 'Composite' value.\n",
    "\n",
    "act17[act17['Composite']=='20.2x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  Participation  English  Math  Reading  Science Composite\n",
       "51  Wyoming            1.0     19.4  19.8     20.8     20.6      20.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the incorrect value with the correct one.\n",
    "\n",
    "act17.loc[act17['Composite']=='20.2x', 'Composite']='20.2'\n",
    "\n",
    "# Checking again to ensure the value is correctly replaced.\n",
    "\n",
    "act17[act17['State']=='Wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17['Composite'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Composite' column values to type float\n",
    "\n",
    "act17['Composite'] = act17['Composite'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data type of the column to ensure it is now of type float.\n",
    "\n",
    "act17['Composite'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.08</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Participation  English  Math  Reading  Science  Composite\n",
       "min  Alabama           0.08     16.3  18.0     18.1      2.3       17.8\n",
       "max  Wyoming           1.00     25.5  25.3     26.0     24.9       25.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeating step from section 4c. above after changing 'Composite' to type float.\n",
    "# Checking min and max values in the ACT 2017 dataset columns to ensure they are within the correct ranges.\n",
    "\n",
    "# Correct ranges as stated above in section 4b.\n",
    "# English, Math, Reading and Science sections' scores: 1 - 36 (inclusive)\n",
    "# Composite score: 1 - 36\n",
    "\n",
    "act17.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama           0.05                                 593   572   1165\n",
       "1      Alaska           0.38                                 547   533   1080\n",
       "2     Arizona           0.30                                 563   553   1116\n",
       "3    Arkansas           0.03                                 614   594   1208\n",
       "4  California           0.53                                 531   524   1055"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                  object\n",
       "Participation                         float64\n",
       "Evidence-Based Reading and Writing      int64\n",
       "Math                                    int64\n",
       "Total                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat17.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>0.60</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  Participation  English  Math  Reading  Science  Composite\n",
       "0  National           0.60     20.3  20.7     21.4     21.0       21.0\n",
       "1   Alabama           1.00     18.9  18.4     19.7     19.4       19.2\n",
       "2    Alaska           0.65     18.7  19.8     20.4     19.9       19.8\n",
       "3   Arizona           0.62     18.6  19.8     20.1     19.8       19.7\n",
       "4  Arkansas           1.00     18.9  19.0     19.7     19.5       19.4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation    float64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dict of new column names for SAT 2017 dataset.\n",
    "\n",
    "sat17_new_columns_dict = {'State' : 'states',\n",
    "                          'Participation' : 'sat17_participation',\n",
    "                          'Evidence-Based Reading and Writing' : 'sat17_ebrw',\n",
    "                          'Math' : 'sat17_math',\n",
    "                          'Total' : 'sat17_total'                        \n",
    "                         }\n",
    "\n",
    "# Renaming column names permanently in the dataset.\n",
    "\n",
    "sat17.rename(columns=sat17_new_columns_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "      <th>sat17_ebrw</th>\n",
       "      <th>sat17_math</th>\n",
       "      <th>sat17_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat17_participation  sat17_ebrw  sat17_math  sat17_total\n",
       "0     Alabama                 0.05         593         572         1165\n",
       "1      Alaska                 0.38         547         533         1080\n",
       "2     Arizona                 0.30         563         553         1116\n",
       "3    Arkansas                 0.03         614         594         1208\n",
       "4  California                 0.53         531         524         1055"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dict of new column names for ACT 2017 dataset.\n",
    "\n",
    "act17_new_columns_dict = {'State' : 'states',\n",
    "                          'Participation' : 'act17_participation',\n",
    "                          'English' : 'act17_english',\n",
    "                          'Math' : 'act17_math',\n",
    "                          'Reading' : 'act17_reading',\n",
    "                          'Science' : 'act17_science',\n",
    "                          'Composite' : 'act17_composite'                        \n",
    "                         }\n",
    "\n",
    "# Renaming column names permanently in the dataset.\n",
    "\n",
    "act17.rename(columns=act17_new_columns_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>act17_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>0.60</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     states  act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0  National                 0.60           20.3        20.7           21.4   \n",
       "1   Alabama                 1.00           18.9        18.4           19.7   \n",
       "2    Alaska                 0.65           18.7        19.8           20.4   \n",
       "3   Arizona                 0.62           18.6        19.8           20.1   \n",
       "4  Arkansas                 1.00           18.9        19.0           19.7   \n",
       "\n",
       "   act17_science  act17_composite  \n",
       "0           21.0             21.0  \n",
       "1           19.4             19.2  \n",
       "2           19.9             19.8  \n",
       "3           19.8             19.7  \n",
       "4           19.5             19.4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---| \n",
    "|**states**|object|ACT 2017, SAT 2017|The states (50) and federal districts (1) of the USA. May also contain one additional 'National' row of data.|\n",
    "|**sat17_participation**|float|SAT 2017|The percentage of students from the graduating class of 2017 who took the 2017 SAT (units percent, where 0.02 represents 2%).|\n",
    "|**sat17_ebrw**|int|SAT 2017|Average scaled scores for the 2017 SAT Evidence-Based Reading and Writing (EBRW) section (without decimal places, in a range of 200 - 800 (inclusive)).|\n",
    "|**sat17_math**|int|SAT 2017|Average scaled scores for the 2017 SAT Math section (without decimal places, in a range of 200 - 800 (inclusive)).|\n",
    "|**sat17_total**|int|SAT 2017|Average scaled total scores for the 2017 SAT (without decimal places, in a range of 400 - 1600 (inclusive)). In SAT, the *individual* total scores are calculated by adding the two sections' scores.|\n",
    "|**act17_participation**|float|ACT 2017|The percentage of students from the graduating class of 2017 who took the 2017 ACT (units percent, where 0.02 represents 2%).|\n",
    "|**act17_english**|float|ACT 2017|Average scaled scores for the 2017 ACT English section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act17_math**|float|ACT 2017|Average scaled scores for the 2017 ACT Math section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act17_reading**|float|ACT 2017|Average scaled scores for the 2017 ACT Reading section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act17_science**|float|ACT 2017|Average scaled scores for the 2017 ACT Science section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act17_composite**|float|ACT 2017|Average scaled composite scores for the 2017 ACT (with one decimal place, in a range of 1 - 36 (inclusive)). In ACT, the *individual* composite scores are calculated by averaging the four sections' scores.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>act17_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     states  act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0  National                  0.6           20.3        20.7           21.4   \n",
       "\n",
       "   act17_science  act17_composite  \n",
       "0           21.0             21.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying and filtering the extra row.\n",
    "\n",
    "act17.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the identified row permanently.\n",
    "\n",
    "act17.drop(0, axis=0, inplace=True)\n",
    "\n",
    "# Reseting the index to start from 0.\n",
    "\n",
    "act17.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>act17_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0     Alabama                 1.00           18.9        18.4           19.7   \n",
       "1      Alaska                 0.65           18.7        19.8           20.4   \n",
       "2     Arizona                 0.62           18.6        19.8           20.1   \n",
       "3    Arkansas                 1.00           18.9        19.0           19.7   \n",
       "4  California                 0.31           22.5        22.7           23.1   \n",
       "\n",
       "   act17_science  act17_composite  \n",
       "0           19.4             19.2  \n",
       "1           19.9             19.8  \n",
       "2           19.8             19.7  \n",
       "3           19.5             19.4  \n",
       "4           22.2             22.8  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two dataframes on the 'states' column and storing it as a new dataframe 'sat_act_17'.\n",
    "\n",
    "# We use 'outer' join to ensure no rows of data are lost in both the datasets.\n",
    "# This will ensure no data loss in case the two datasets happen to have one (or more) state names\n",
    "# which have not been typed identically in the two datasets by mistake (or for some other reason).\n",
    "\n",
    "sat_act_17 = pd.merge(sat17, act17, on='states', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 11)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of combined dataframe to ensure it still only has 51 rows of data.\n",
    "# If combined dataframe has 51 rows of data, it means that all 51 state names matched together identically between the\n",
    "# two datasets, and no empty values exist in the combined dataframe.\n",
    "\n",
    "sat_act_17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "      <th>sat17_ebrw</th>\n",
       "      <th>sat17_math</th>\n",
       "      <th>sat17_total</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>act17_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat17_participation  sat17_ebrw  sat17_math  sat17_total  \\\n",
       "0     Alabama                 0.05         593         572         1165   \n",
       "1      Alaska                 0.38         547         533         1080   \n",
       "2     Arizona                 0.30         563         553         1116   \n",
       "3    Arkansas                 0.03         614         594         1208   \n",
       "4  California                 0.53         531         524         1055   \n",
       "\n",
       "   act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0                 1.00           18.9        18.4           19.7   \n",
       "1                 0.65           18.7        19.8           20.4   \n",
       "2                 0.62           18.6        19.8           20.1   \n",
       "3                 1.00           18.9        19.0           19.7   \n",
       "4                 0.31           22.5        22.7           23.1   \n",
       "\n",
       "   act17_science  act17_composite  \n",
       "0           19.4             19.2  \n",
       "1           19.9             19.8  \n",
       "2           19.8             19.7  \n",
       "3           19.5             19.4  \n",
       "4           22.2             22.8  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_act_17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the merged dataframe to a CSV file using a relative path.\n",
    "\n",
    "sat_act_17.to_csv('../data/combined_2017.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV files using relative filepaths\n",
    "\n",
    "sat18 = pd.read_csv(\"../data/sat_2018.csv\")\n",
    "act18 = pd.read_csv(\"../data/act_2018_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>519</td>\n",
       "      <td>506</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>535</td>\n",
       "      <td>519</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>505</td>\n",
       "      <td>492</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>92%</td>\n",
       "      <td>497</td>\n",
       "      <td>480</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>56%</td>\n",
       "      <td>550</td>\n",
       "      <td>549</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            6%                                 595   \n",
       "1                Alaska           43%                                 562   \n",
       "2               Arizona           29%                                 577   \n",
       "3              Arkansas            5%                                 592   \n",
       "4            California           60%                                 540   \n",
       "5              Colorado          100%                                 519   \n",
       "6           Connecticut          100%                                 535   \n",
       "7              Delaware          100%                                 505   \n",
       "8  District of Columbia           92%                                 497   \n",
       "9               Florida           56%                                 550   \n",
       "\n",
       "   Math  Total  \n",
       "0   571   1166  \n",
       "1   544   1106  \n",
       "2   572   1149  \n",
       "3   576   1169  \n",
       "4   536   1076  \n",
       "5   506   1025  \n",
       "6   519   1053  \n",
       "7   492    998  \n",
       "8   480    977  \n",
       "9   549   1099  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing a few lines of each dataframe to ensure that it was read properly.\n",
    "\n",
    "sat18.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>68%</td>\n",
       "      <td>567</td>\n",
       "      <td>550</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>69%</td>\n",
       "      <td>543</td>\n",
       "      <td>538</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>28%</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3%</td>\n",
       "      <td>641</td>\n",
       "      <td>653</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3%</td>\n",
       "      <td>633</td>\n",
       "      <td>625</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "46       Virginia           68%                                 567   550   \n",
       "47     Washington           69%                                 543   538   \n",
       "48  West Virginia           28%                                 513   486   \n",
       "49      Wisconsin            3%                                 641   653   \n",
       "50        Wyoming            3%                                 633   625   \n",
       "\n",
       "    Total  \n",
       "46   1117  \n",
       "47   1081  \n",
       "48    999  \n",
       "49   1294  \n",
       "50   1257  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat18.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows in the dataframe to ensure it is 51 (same as sat17).\n",
    "\n",
    "len(sat18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of values in the 'State' column to ensure it is 51 (same as sat17).\n",
    "\n",
    "len(sat18['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "       'North Dakota', 'Oklahoma', 'Ohio', 'Oregon', 'Pennsylvania',\n",
       "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "       'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in the 'State' column.\n",
    "\n",
    "sat18['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Percentage of Students Tested</th>\n",
       "      <th>Average Composite Score</th>\n",
       "      <th>Average English Score</th>\n",
       "      <th>Average Math Score</th>\n",
       "      <th>Average Reading Score</th>\n",
       "      <th>Average Science Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>30</td>\n",
       "      <td>23.9</td>\n",
       "      <td>23.9</td>\n",
       "      <td>23.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>26</td>\n",
       "      <td>25.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.1</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>17</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>66</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State  Percentage of Students Tested  \\\n",
       "0               Alabama                            100   \n",
       "1                Alaska                             33   \n",
       "2               Arizona                             66   \n",
       "3              Arkansas                            100   \n",
       "4            California                             27   \n",
       "5              Colorado                             30   \n",
       "6           Connecticut                             26   \n",
       "7              Delaware                             17   \n",
       "8  District of Columbia                             32   \n",
       "9               Florida                             66   \n",
       "\n",
       "   Average Composite Score  Average English Score  Average Math Score  \\\n",
       "0                     19.1                   18.9                18.3   \n",
       "1                     20.8                   19.8                20.6   \n",
       "2                     19.2                   18.2                19.4   \n",
       "3                     19.4                   19.1                18.9   \n",
       "4                     22.7                   22.5                22.5   \n",
       "5                     23.9                   23.9                23.2   \n",
       "6                     25.6                   26.0                24.8   \n",
       "7                     23.2                   23.7                23.1   \n",
       "8                     23.6                   23.7                22.7   \n",
       "9                     19.9                   19.2                19.3   \n",
       "\n",
       "   Average Reading Score  Average Science Score  \n",
       "0                   19.6                   19.0  \n",
       "1                   21.6                   20.7  \n",
       "2                   19.5                   19.2  \n",
       "3                   19.7                   19.4  \n",
       "4                   23.0                   22.1  \n",
       "5                   24.4                   23.5  \n",
       "6                   26.1                   24.9  \n",
       "7                   24.5                   23.4  \n",
       "8                   24.4                   23.0  \n",
       "9                   21.1                   19.5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Percentage of Students Tested</th>\n",
       "      <th>Average Composite Score</th>\n",
       "      <th>Average English Score</th>\n",
       "      <th>Average Math Score</th>\n",
       "      <th>Average Reading Score</th>\n",
       "      <th>Average Science Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>24</td>\n",
       "      <td>23.9</td>\n",
       "      <td>23.8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.7</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>24</td>\n",
       "      <td>22.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.7</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>65</td>\n",
       "      <td>20.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Percentage of Students Tested  Average Composite Score  \\\n",
       "46       Virginia                             24                     23.9   \n",
       "47     Washington                             24                     22.2   \n",
       "48  West Virginia                             65                     20.3   \n",
       "49      Wisconsin                            100                     20.5   \n",
       "50        Wyoming                            100                     20.0   \n",
       "\n",
       "    Average English Score  Average Math Score  Average Reading Score  \\\n",
       "46                   23.8                23.3                   24.7   \n",
       "47                   21.4                22.2                   22.7   \n",
       "48                   19.8                19.4                   21.3   \n",
       "49                   19.8                20.3                   20.6   \n",
       "50                   19.0                19.7                   20.6   \n",
       "\n",
       "    Average Science Score  \n",
       "46                   23.5  \n",
       "47                   22.0  \n",
       "48                   20.4  \n",
       "49                   20.8  \n",
       "50                   20.3  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows in the dataframe to ensure it is 51 (same as act17).\n",
    "\n",
    "len(act18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of values in the 'State' column to ensure it is 51 (same as act17).\n",
    "\n",
    "len(act18['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "       'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "       'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in the 'State' column.\n",
    "\n",
    "act18['State'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of SAT 2018 and ACT 2018 datasets**\n",
    "\n",
    "**SAT 2018:** Similar to SAT 2017, this dataset *(imported here as 'sat18')* provides a breakdown of the 2018 SAT participation rates *(column 'Participation')*, average scores for EBRW and Math sections *(columns 'Evidence-Based Reading and Writing' and 'Math', respectively)* and the average aggregate scores *(column 'Total')* for all 50 states and 1 federal district (District of Columbia) of the USA *(column 'State', arranged alphabetically)*.\n",
    "\n",
    "The values in the 'State' column are *strings*. The numerical values of the scores in the dataset do not carry any decimal places, and so should be expected to be *integers*. The values in the 'Participation' column carry a numerical value followed by a % symbol. So, these should be expected to be *strings* which would need to be converted to *floats*.\n",
    "\n",
    "**ACT 2018:** Similar to ACT 2017, this dataset *(imported here as 'act18')* provides a breakdown of the 2018 ACT participation rates *(column 'Percentage of Students Tested')*, average scores for English, Math, Reading and Science sections *(columns 'Average English Score', 'Average Math Score', 'Average Reading Score' and 'Average Science Score', respectively)* and the average composite scores *(column 'Average Composite Score')* for all 50 states and 1 federal district (District of Columbia) of the USA *(column 'State', arranged alphabetically)*.\n",
    "\n",
    "The values in the 'State' column are *strings*. The numerical values of the scores in the dataset carry decimal places, and so should be expected to be *floats*. The values in the 'Percentage of Students Tested' column carry a numerical value, so should be expected to be *integers*. However, in order to maintain consistency with SAT 2017, ACT 2017 & SAT 2018 datasets, these values would need to be converted to *floats*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick visual inspection of the datasets**\n",
    "\n",
    "*The description in this section is ONLY based on a quick visual inspection of the CSV files. This method may be usable here because the datasets are relatively small in size (only 5-7 columns, ~51 rows).*\n",
    "\n",
    "As explained in section 4b. above, for the **SAT**, the ranges for possible 'scaled scores' for each of the **2 setions** are **200 - 800 (inclusive)**. The total score is calculated by adding the 2 sections' scores, thus giving a possible **total score range of 400 - 1600**.\n",
    "\n",
    "A quick visual inspection of the sat_2018 CSV file did not reveal any abnormal values. All values will still have to be checked using code, to ensure that they are within the correct ranges and of the correct data types (which may have been missed during the visual inspection).\n",
    "\n",
    "As explained in section 4b. above, for the **ACT**, the ranges for possible 'scaled scores' for each of the **4 sections** are **1 - 36 (inclusive)**. The composite score is calculated by averaging the 4 sections' scores, thus giving a possible **composite score range of 1 - 36**.\n",
    "\n",
    "A quick visual inspection of the act_2018_updated CSV file did not reveal any abnormal values. All values will still have to be checked using code, to ensure that they are within the correct ranges and of the correct data types (which may have been missed during the visual inspection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      "State                                 51 non-null object\n",
      "Participation                         51 non-null object\n",
      "Evidence-Based Reading and Writing    51 non-null int64\n",
      "Math                                  51 non-null int64\n",
      "Total                                 51 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset info to verify data types of the columns and any missing values.\n",
    "\n",
    "sat18.info()\n",
    "\n",
    "# All numerical columns in this dataset have the correct data type int.\n",
    "# No missing values are present in the dataset.\n",
    "# 'Participation' column will have to be converted to type 'float' (similar to SAT 2017 and ACT 2017 datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 7 columns):\n",
      "State                            51 non-null object\n",
      "Percentage of Students Tested    51 non-null int64\n",
      "Average Composite Score          51 non-null float64\n",
      "Average English Score            51 non-null float64\n",
      "Average Math Score               51 non-null float64\n",
      "Average Reading Score            51 non-null float64\n",
      "Average Science Score            51 non-null float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset info to verify data types of the columns and any missing values.\n",
    "\n",
    "act18.info()\n",
    "\n",
    "# All numerical columns in this dataset have the correct data type float.\n",
    "# No missing values are present in the dataset.\n",
    "# 'Participation' column will have to be converted to type 'float' (similar to SAT 2017 and ACT 2017 datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>10%</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>99%</td>\n",
       "      <td>643</td>\n",
       "      <td>655</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "min  Alabama           10%                                 480   480    977\n",
       "max  Wyoming           99%                                 643   655   1298"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking min and max values in the SAT 2018 dataset columns to ensure they are within the correct ranges.\n",
    "\n",
    "# Correct ranges as stated above in section 4b.\n",
    "# EBRW and Math sections' scores: 200 - 800 (inclusive)\n",
    "# Total score: 400 - 1600\n",
    "\n",
    "sat18.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Percentage of Students Tested</th>\n",
       "      <th>Average Composite Score</th>\n",
       "      <th>Average English Score</th>\n",
       "      <th>Average Math Score</th>\n",
       "      <th>Average Reading Score</th>\n",
       "      <th>Average Science Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100</td>\n",
       "      <td>25.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>26.1</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Percentage of Students Tested  Average Composite Score  \\\n",
       "min  Alabama                              7                     17.7   \n",
       "max  Wyoming                            100                     25.6   \n",
       "\n",
       "     Average English Score  Average Math Score  Average Reading Score  \\\n",
       "min                   16.6                17.8                   18.0   \n",
       "max                   26.0                25.2                   26.1   \n",
       "\n",
       "     Average Science Score  \n",
       "min                   17.9  \n",
       "max                   24.9  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking min and max values in the ACT 2018 dataset columns to ensure they are within the correct ranges.\n",
    "\n",
    "# Correct ranges as stated above in section 4b.\n",
    "# English, Math, Reading and Science sections' scores: 1 - 36 (inclusive)\n",
    "# Composite score: 1 - 36\n",
    "\n",
    "act18.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SAT 2018 dataset\n",
    "# Converting 'Participation' column from type object to type float by removing the % symbol after all numerical values.\n",
    "# lambda function replaces the '%' in the strings with '' and then converts them to float.\n",
    "# All float values are divided by 100 because they are percentages.\n",
    "# .map funtion maps the lambda function to all values in 'Participation' column.\n",
    "\n",
    "sat18['Participation'] = sat18[\"Participation\"].map(lambda pct : float(pct.replace(\"%\", \"\"))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                  object\n",
       "Participation                         float64\n",
       "Evidence-Based Reading and Writing      int64\n",
       "Math                                    int64\n",
       "Total                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data type of the columns again to ensure they are now all correct.\n",
    "\n",
    "sat18.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama           0.06                                 595   571   1166\n",
       "1      Alaska           0.43                                 562   544   1106\n",
       "2     Arizona           0.29                                 577   572   1149\n",
       "3    Arkansas           0.05                                 592   576   1169\n",
       "4  California           0.60                                 540   536   1076"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ACT 2018 dataset\n",
    "# Converting 'Percentage of Students Tested' column from type int to type float.\n",
    "# All float values are divided by 100 because they are percentages.\n",
    "\n",
    "act18['Percentage of Students Tested'] = act18[\"Percentage of Students Tested\"].astype(float) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                             object\n",
       "Percentage of Students Tested    float64\n",
       "Average Composite Score          float64\n",
       "Average English Score            float64\n",
       "Average Math Score               float64\n",
       "Average Reading Score            float64\n",
       "Average Science Score            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data type of the columns again to ensure they are now all correct.\n",
    "\n",
    "act18.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Percentage of Students Tested</th>\n",
       "      <th>Average Composite Score</th>\n",
       "      <th>Average English Score</th>\n",
       "      <th>Average Math Score</th>\n",
       "      <th>Average Reading Score</th>\n",
       "      <th>Average Science Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Percentage of Students Tested  Average Composite Score  \\\n",
       "0     Alabama                           1.00                     19.1   \n",
       "1      Alaska                           0.33                     20.8   \n",
       "2     Arizona                           0.66                     19.2   \n",
       "3    Arkansas                           1.00                     19.4   \n",
       "4  California                           0.27                     22.7   \n",
       "\n",
       "   Average English Score  Average Math Score  Average Reading Score  \\\n",
       "0                   18.9                18.3                   19.6   \n",
       "1                   19.8                20.6                   21.6   \n",
       "2                   18.2                19.4                   19.5   \n",
       "3                   19.1                18.9                   19.7   \n",
       "4                   22.5                22.5                   23.0   \n",
       "\n",
       "   Average Science Score  \n",
       "0                   19.0  \n",
       "1                   20.7  \n",
       "2                   19.2  \n",
       "3                   19.4  \n",
       "4                   22.1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dict of new column names for SAT 2018 dataset.\n",
    "\n",
    "sat18_new_columns_dict = {'State' : 'states',\n",
    "                          'Participation' : 'sat18_participation',\n",
    "                          'Evidence-Based Reading and Writing' : 'sat18_ebrw',\n",
    "                          'Math' : 'sat18_math',\n",
    "                          'Total' : 'sat18_total'                        \n",
    "                         }\n",
    "\n",
    "# Renaming column names permanently in the dataset.\n",
    "\n",
    "sat18.rename(columns=sat18_new_columns_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat18_participation</th>\n",
       "      <th>sat18_ebrw</th>\n",
       "      <th>sat18_math</th>\n",
       "      <th>sat18_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat18_participation  sat18_ebrw  sat18_math  sat18_total\n",
       "0     Alabama                 0.06         595         571         1166\n",
       "1      Alaska                 0.43         562         544         1106\n",
       "2     Arizona                 0.29         577         572         1149\n",
       "3    Arkansas                 0.05         592         576         1169\n",
       "4  California                 0.60         540         536         1076"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dict of new column names for ACT 2018 dataset.\n",
    "\n",
    "act18_new_columns_dict = {'State' : 'states',\n",
    "                          'Percentage of Students Tested' : 'act18_participation',\n",
    "                          'Average English Score' : 'act18_english',\n",
    "                          'Average Math Score' : 'act18_math',\n",
    "                          'Average Reading Score' : 'act18_reading',\n",
    "                          'Average Science Score' : 'act18_science',\n",
    "                          'Average Composite Score' : 'act18_composite'                        \n",
    "                         }\n",
    "\n",
    "# Renaming column names permanently in the dataset.\n",
    "\n",
    "act18.rename(columns=act18_new_columns_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act18_participation</th>\n",
       "      <th>act18_composite</th>\n",
       "      <th>act18_english</th>\n",
       "      <th>act18_math</th>\n",
       "      <th>act18_reading</th>\n",
       "      <th>act18_science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  act18_participation  act18_composite  act18_english  \\\n",
       "0     Alabama                 1.00             19.1           18.9   \n",
       "1      Alaska                 0.33             20.8           19.8   \n",
       "2     Arizona                 0.66             19.2           18.2   \n",
       "3    Arkansas                 1.00             19.4           19.1   \n",
       "4  California                 0.27             22.7           22.5   \n",
       "\n",
       "   act18_math  act18_reading  act18_science  \n",
       "0        18.3           19.6           19.0  \n",
       "1        20.6           21.6           20.7  \n",
       "2        19.4           19.5           19.2  \n",
       "3        18.9           19.7           19.4  \n",
       "4        22.5           23.0           22.1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arranging the order of columns to maintain consistency with ACT 2017 dataset.\n",
    "\n",
    "act18 = act18[['states', 'act18_participation', 'act18_english', 'act18_math', 'act18_reading', 'act18_science', 'act18_composite']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act18_participation</th>\n",
       "      <th>act18_english</th>\n",
       "      <th>act18_math</th>\n",
       "      <th>act18_reading</th>\n",
       "      <th>act18_science</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  act18_participation  act18_english  act18_math  act18_reading  \\\n",
       "0     Alabama                 1.00           18.9        18.3           19.6   \n",
       "1      Alaska                 0.33           19.8        20.6           21.6   \n",
       "2     Arizona                 0.66           18.2        19.4           19.5   \n",
       "3    Arkansas                 1.00           19.1        18.9           19.7   \n",
       "4  California                 0.27           22.5        22.5           23.0   \n",
       "\n",
       "   act18_science  act18_composite  \n",
       "0           19.0             19.1  \n",
       "1           20.7             20.8  \n",
       "2           19.2             19.2  \n",
       "3           19.4             19.4  \n",
       "4           22.1             22.7  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---| \n",
    "|**states**|object|ACT 2018, SAT 2018|The states (50) and federal districts (1) of the USA.|\n",
    "|**sat18_participation**|float|SAT 2018|The percentage of students from the graduating class of 2018 who took the 2018 SAT (units percent, where 0.02 represents 2%).|\n",
    "|**sat18_ebrw**|int|SAT 2018|Average scaled scores for the 2018 SAT Evidence-Based Reading and Writing (EBRW) section (without decimal places, in a range of 200 - 800 (inclusive)).|\n",
    "|**sat18_math**|int|SAT 2018|Average scaled scores for the 2018 SAT Math section (without decimal places, in a range of 200 - 800 (inclusive)).|\n",
    "|**sat18_total**|int|SAT 2018|Average scaled total scores for the 2018 SAT (without decimal places, in a range of 400 - 1600 (inclusive)). In SAT, the *individual* total scores are calculated by adding the two sections' scores.|\n",
    "|**act18_participation**|float|ACT 2018|The percentage of students from the graduating class of 2018 who took the 2018 ACT (units percent, where 0.02 represents 2%).|\n",
    "|**act18_english**|float|ACT 2018|Average scaled scores for the 2018 ACT English section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act18_math**|float|ACT 2018|Average scaled scores for the 2018 ACT Math section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act18_reading**|float|ACT 2018|Average scaled scores for the 2018 ACT Reading section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act18_science**|float|ACT 2018|Average scaled scores for the 2018 ACT Science section (with one decimal place, in a range of 1 - 36 (inclusive)).|\n",
    "|**act18_composite**|float|ACT 2018|Average scaled composite scores for the 2018 ACT (with one decimal place, in a range of 1 - 36 (inclusive)). In ACT, the *individual* composite scores are calculated by averaging the four sections' scores.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two dataframes on the 'states' column and storing it as a new dataframe 'sat_act_18'.\n",
    "\n",
    "# We use 'outer' join to ensure no rows of data are lost in both the datasets.\n",
    "# This will ensure no data loss in case the two datasets happen to have one (or more) state names\n",
    "# which have not been typed identically in the two datasets by mistake (or for some other reason).\n",
    "\n",
    "sat_act_18 = pd.merge(sat18, act18, on='states', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 11)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of combined dataframe to ensure it still only has 51 rows of data.\n",
    "# If combined dataframe has 51 rows of data, it means that all 51 state names matched together identically between the\n",
    "# two datasets, and no empty values exist in the combined dataframe.\n",
    "\n",
    "sat_act_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat18_participation</th>\n",
       "      <th>sat18_ebrw</th>\n",
       "      <th>sat18_math</th>\n",
       "      <th>sat18_total</th>\n",
       "      <th>act18_participation</th>\n",
       "      <th>act18_english</th>\n",
       "      <th>act18_math</th>\n",
       "      <th>act18_reading</th>\n",
       "      <th>act18_science</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat18_participation  sat18_ebrw  sat18_math  sat18_total  \\\n",
       "0     Alabama                 0.06         595         571         1166   \n",
       "1      Alaska                 0.43         562         544         1106   \n",
       "2     Arizona                 0.29         577         572         1149   \n",
       "3    Arkansas                 0.05         592         576         1169   \n",
       "4  California                 0.60         540         536         1076   \n",
       "\n",
       "   act18_participation  act18_english  act18_math  act18_reading  \\\n",
       "0                 1.00           18.9        18.3           19.6   \n",
       "1                 0.33           19.8        20.6           21.6   \n",
       "2                 0.66           18.2        19.4           19.5   \n",
       "3                 1.00           19.1        18.9           19.7   \n",
       "4                 0.27           22.5        22.5           23.0   \n",
       "\n",
       "   act18_science  act18_composite  \n",
       "0           19.0             19.1  \n",
       "1           20.7             20.8  \n",
       "2           19.2             19.2  \n",
       "3           19.4             19.4  \n",
       "4           22.1             22.7  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_act_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the merged dataframe to a CSV file using a relative path.\n",
    "\n",
    "sat_act_18.to_csv('../data/combined_2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two dataframes on the 'states' column and storing it as a new dataframe 'satact_1718'.\n",
    "\n",
    "# We use 'outer' join to ensure no rows of data are lost in both the datasets.\n",
    "# This will ensure no data loss in case the two datasets happen to have one (or more) state names\n",
    "# which have not been typed identically in the two datasets by mistake (or for some other reason).\n",
    "\n",
    "satact_1718 = pd.merge(sat_act_17, sat_act_18, on='states', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "      <th>sat17_ebrw</th>\n",
       "      <th>sat17_math</th>\n",
       "      <th>sat17_total</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>...</th>\n",
       "      <th>sat18_participation</th>\n",
       "      <th>sat18_ebrw</th>\n",
       "      <th>sat18_math</th>\n",
       "      <th>sat18_total</th>\n",
       "      <th>act18_participation</th>\n",
       "      <th>act18_english</th>\n",
       "      <th>act18_math</th>\n",
       "      <th>act18_reading</th>\n",
       "      <th>act18_science</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat17_participation  sat17_ebrw  sat17_math  sat17_total  \\\n",
       "0     Alabama                 0.05         593         572         1165   \n",
       "1      Alaska                 0.38         547         533         1080   \n",
       "2     Arizona                 0.30         563         553         1116   \n",
       "3    Arkansas                 0.03         614         594         1208   \n",
       "4  California                 0.53         531         524         1055   \n",
       "\n",
       "   act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0                 1.00           18.9        18.4           19.7   \n",
       "1                 0.65           18.7        19.8           20.4   \n",
       "2                 0.62           18.6        19.8           20.1   \n",
       "3                 1.00           18.9        19.0           19.7   \n",
       "4                 0.31           22.5        22.7           23.1   \n",
       "\n",
       "   act17_science  ...  sat18_participation  sat18_ebrw  sat18_math  \\\n",
       "0           19.4  ...                 0.06         595         571   \n",
       "1           19.9  ...                 0.43         562         544   \n",
       "2           19.8  ...                 0.29         577         572   \n",
       "3           19.5  ...                 0.05         592         576   \n",
       "4           22.2  ...                 0.60         540         536   \n",
       "\n",
       "   sat18_total  act18_participation  act18_english  act18_math  act18_reading  \\\n",
       "0         1166                 1.00           18.9        18.3           19.6   \n",
       "1         1106                 0.33           19.8        20.6           21.6   \n",
       "2         1149                 0.66           18.2        19.4           19.5   \n",
       "3         1169                 1.00           19.1        18.9           19.7   \n",
       "4         1076                 0.27           22.5        22.5           23.0   \n",
       "\n",
       "   act18_science  act18_composite  \n",
       "0           19.0             19.1  \n",
       "1           20.7             20.8  \n",
       "2           19.2             19.2  \n",
       "3           19.4             19.4  \n",
       "4           22.1             22.7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satact_1718.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the merged dataframe to a CSV file using a relative path.\n",
    "\n",
    "satact_1718.to_csv('../data/final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat17_participation</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.398039</td>\n",
       "      <td>0.352766</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat17_ebrw</th>\n",
       "      <td>51.0</td>\n",
       "      <td>569.117647</td>\n",
       "      <td>45.666901</td>\n",
       "      <td>482.00</td>\n",
       "      <td>533.500</td>\n",
       "      <td>559.00</td>\n",
       "      <td>613.000</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat17_math</th>\n",
       "      <td>51.0</td>\n",
       "      <td>556.882353</td>\n",
       "      <td>47.121395</td>\n",
       "      <td>468.00</td>\n",
       "      <td>523.500</td>\n",
       "      <td>548.00</td>\n",
       "      <td>599.000</td>\n",
       "      <td>651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat17_total</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1126.098039</td>\n",
       "      <td>92.494812</td>\n",
       "      <td>950.00</td>\n",
       "      <td>1055.500</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>1212.000</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_participation</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.652549</td>\n",
       "      <td>0.321408</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_english</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.931373</td>\n",
       "      <td>2.353677</td>\n",
       "      <td>16.30</td>\n",
       "      <td>19.000</td>\n",
       "      <td>20.70</td>\n",
       "      <td>23.300</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_math</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.182353</td>\n",
       "      <td>1.981989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>19.400</td>\n",
       "      <td>20.90</td>\n",
       "      <td>23.100</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_reading</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.013725</td>\n",
       "      <td>2.067271</td>\n",
       "      <td>18.10</td>\n",
       "      <td>20.450</td>\n",
       "      <td>21.80</td>\n",
       "      <td>24.150</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_science</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.041176</td>\n",
       "      <td>3.182463</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.900</td>\n",
       "      <td>21.30</td>\n",
       "      <td>22.750</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act17_composite</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.519608</td>\n",
       "      <td>2.020695</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.800</td>\n",
       "      <td>21.40</td>\n",
       "      <td>23.600</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat18_participation</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.457451</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat18_ebrw</th>\n",
       "      <td>51.0</td>\n",
       "      <td>563.686275</td>\n",
       "      <td>47.502627</td>\n",
       "      <td>480.00</td>\n",
       "      <td>534.500</td>\n",
       "      <td>552.00</td>\n",
       "      <td>610.500</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat18_math</th>\n",
       "      <td>51.0</td>\n",
       "      <td>556.235294</td>\n",
       "      <td>47.772623</td>\n",
       "      <td>480.00</td>\n",
       "      <td>522.500</td>\n",
       "      <td>544.00</td>\n",
       "      <td>593.500</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat18_total</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1120.019608</td>\n",
       "      <td>94.155083</td>\n",
       "      <td>977.00</td>\n",
       "      <td>1057.500</td>\n",
       "      <td>1098.00</td>\n",
       "      <td>1204.000</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_participation</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.616471</td>\n",
       "      <td>0.340810</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_english</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.988235</td>\n",
       "      <td>2.446356</td>\n",
       "      <td>16.60</td>\n",
       "      <td>19.100</td>\n",
       "      <td>20.20</td>\n",
       "      <td>23.700</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_math</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.125490</td>\n",
       "      <td>2.035765</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.400</td>\n",
       "      <td>20.70</td>\n",
       "      <td>23.150</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_reading</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.015686</td>\n",
       "      <td>2.167245</td>\n",
       "      <td>18.00</td>\n",
       "      <td>20.450</td>\n",
       "      <td>21.60</td>\n",
       "      <td>24.100</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_science</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.345098</td>\n",
       "      <td>1.870114</td>\n",
       "      <td>17.90</td>\n",
       "      <td>19.850</td>\n",
       "      <td>21.10</td>\n",
       "      <td>23.050</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act18_composite</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.486275</td>\n",
       "      <td>2.106278</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.950</td>\n",
       "      <td>21.30</td>\n",
       "      <td>23.550</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count         mean        std     min       25%      50%  \\\n",
       "sat17_participation   51.0     0.398039   0.352766    0.02     0.040     0.38   \n",
       "sat17_ebrw            51.0   569.117647  45.666901  482.00   533.500   559.00   \n",
       "sat17_math            51.0   556.882353  47.121395  468.00   523.500   548.00   \n",
       "sat17_total           51.0  1126.098039  92.494812  950.00  1055.500  1107.00   \n",
       "act17_participation   51.0     0.652549   0.321408    0.08     0.310     0.69   \n",
       "act17_english         51.0    20.931373   2.353677   16.30    19.000    20.70   \n",
       "act17_math            51.0    21.182353   1.981989   18.00    19.400    20.90   \n",
       "act17_reading         51.0    22.013725   2.067271   18.10    20.450    21.80   \n",
       "act17_science         51.0    21.041176   3.182463    2.30    19.900    21.30   \n",
       "act17_composite       51.0    21.519608   2.020695   17.80    19.800    21.40   \n",
       "sat18_participation   51.0     0.457451   0.373143    0.02     0.045     0.52   \n",
       "sat18_ebrw            51.0   563.686275  47.502627  480.00   534.500   552.00   \n",
       "sat18_math            51.0   556.235294  47.772623  480.00   522.500   544.00   \n",
       "sat18_total           51.0  1120.019608  94.155083  977.00  1057.500  1098.00   \n",
       "act18_participation   51.0     0.616471   0.340810    0.07     0.285     0.66   \n",
       "act18_english         51.0    20.988235   2.446356   16.60    19.100    20.20   \n",
       "act18_math            51.0    21.125490   2.035765   17.80    19.400    20.70   \n",
       "act18_reading         51.0    22.015686   2.167245   18.00    20.450    21.60   \n",
       "act18_science         51.0    21.345098   1.870114   17.90    19.850    21.10   \n",
       "act18_composite       51.0    21.486275   2.106278   17.70    19.950    21.30   \n",
       "\n",
       "                          75%     max  \n",
       "sat17_participation     0.660     1.0  \n",
       "sat17_ebrw            613.000   644.0  \n",
       "sat17_math            599.000   651.0  \n",
       "sat17_total          1212.000  1295.0  \n",
       "act17_participation     1.000     1.0  \n",
       "act17_english          23.300    25.5  \n",
       "act17_math             23.100    25.3  \n",
       "act17_reading          24.150    26.0  \n",
       "act17_science          22.750    24.9  \n",
       "act17_composite        23.600    25.5  \n",
       "sat18_participation     0.775     1.0  \n",
       "sat18_ebrw            610.500   643.0  \n",
       "sat18_math            593.500   655.0  \n",
       "sat18_total          1204.000  1298.0  \n",
       "act18_participation     1.000     1.0  \n",
       "act18_english          23.700    26.0  \n",
       "act18_math             23.150    25.2  \n",
       "act18_reading          24.100    26.1  \n",
       "act18_science          23.050    24.9  \n",
       "act18_composite        23.550    25.6  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satact_1718.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate standard deviation of a series of data.\n",
    "# The function takes the column as an input and returns the standard deviation of the values in the column (calculated using the above formula).\n",
    "\n",
    "def calculate_stdev(col):\n",
    "    n = len(col)\n",
    "    mean = col.sum() / n\n",
    "    diff = 0\n",
    "    for val in col:\n",
    "        diff += (val-mean)**2\n",
    "    std = (diff/n)**0.5\n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating stdev of all numeric columns and storing them in a new variable using dictionary comprehension.\n",
    "# 1. Filter out the numeric columns using .iloc and convert the filtered dataframe into a dictionary using dict().\n",
    "# 2. Using dictionary comprehension, store the column names as keys and the returned stdev values from calculate_stdev function\n",
    "#    as values into a new dictionary called 'sd'.\n",
    "\n",
    "sd = {col_name : calculate_stdev(vals) for col_name, vals in dict(satact_1718.iloc[:, 1:]).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sat17_participation': 0.3492907076664507,\n",
       " 'sat17_ebrw': 45.21697020437866,\n",
       " 'sat17_math': 46.65713364485503,\n",
       " 'sat17_total': 91.58351056778743,\n",
       " 'act17_participation': 0.3182417575123181,\n",
       " 'act17_english': 2.3304876369363363,\n",
       " 'act17_math': 1.9624620273436781,\n",
       " 'act17_reading': 2.0469029314842646,\n",
       " 'act17_science': 3.151107895464408,\n",
       " 'act17_composite': 2.000786081581989,\n",
       " 'sat18_participation': 0.3694661922353941,\n",
       " 'sat18_ebrw': 47.03460978357609,\n",
       " 'sat18_math': 47.30194550378352,\n",
       " 'sat18_total': 93.22742384464433,\n",
       " 'act18_participation': 0.33745194881997503,\n",
       " 'act18_english': 2.4222536143202795,\n",
       " 'act18_math': 2.0157072555557174,\n",
       " 'act18_reading': 2.145891884510421,\n",
       " 'act18_science': 1.851688548483354,\n",
       " 'act18_composite': 2.0855261815801147}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.58351056778743"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using np.std to calculate stdev of 'sat17_total' column.\n",
    "\n",
    "np.std(satact_1718['sat17_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.49481172519046"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pd.DataFrame.std to calculate stdev of 'sat17_total' column.\n",
    "# Argument delta degrees of freedom (ddof) set to 1 by default.\n",
    "\n",
    "satact_1718['sat17_total'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.58351056778743"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pd.DataFrame.std to calculate stdev of 'sat17_total' column.\n",
    "# Setting delta degrees of freedom (ddof) to 0.\n",
    "\n",
    "satact_1718['sat17_total'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We notice that the manually calculated values of standard deviation are same as the ones calculated using *np.std* method. This is because *np.std* has an argument for delta degrees of freedom *(ddof)*, which is set to 0 by default.\n",
    "\n",
    "The values we obtained using *pd.DataFrame.describe()* were different because the argument *ddof* is set to 1 by default. This is also the case in *pd.DataFrame.std()*. When we explicitly set *ddof = 0*, we obtain the stdev values which are same as *np.std* and our manually calculating function *(calculate_stdev(col))*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "      <th>sat17_ebrw</th>\n",
       "      <th>sat17_math</th>\n",
       "      <th>sat17_total</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act17_english</th>\n",
       "      <th>act17_math</th>\n",
       "      <th>act17_reading</th>\n",
       "      <th>act17_science</th>\n",
       "      <th>...</th>\n",
       "      <th>sat18_participation</th>\n",
       "      <th>sat18_ebrw</th>\n",
       "      <th>sat18_math</th>\n",
       "      <th>sat18_total</th>\n",
       "      <th>act18_participation</th>\n",
       "      <th>act18_english</th>\n",
       "      <th>act18_math</th>\n",
       "      <th>act18_reading</th>\n",
       "      <th>act18_science</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       states  sat17_participation  sat17_ebrw  sat17_math  sat17_total  \\\n",
       "0     Alabama                 0.05         593         572         1165   \n",
       "1      Alaska                 0.38         547         533         1080   \n",
       "2     Arizona                 0.30         563         553         1116   \n",
       "3    Arkansas                 0.03         614         594         1208   \n",
       "4  California                 0.53         531         524         1055   \n",
       "\n",
       "   act17_participation  act17_english  act17_math  act17_reading  \\\n",
       "0                 1.00           18.9        18.4           19.7   \n",
       "1                 0.65           18.7        19.8           20.4   \n",
       "2                 0.62           18.6        19.8           20.1   \n",
       "3                 1.00           18.9        19.0           19.7   \n",
       "4                 0.31           22.5        22.7           23.1   \n",
       "\n",
       "   act17_science  ...  sat18_participation  sat18_ebrw  sat18_math  \\\n",
       "0           19.4  ...                 0.06         595         571   \n",
       "1           19.9  ...                 0.43         562         544   \n",
       "2           19.8  ...                 0.29         577         572   \n",
       "3           19.5  ...                 0.05         592         576   \n",
       "4           22.2  ...                 0.60         540         536   \n",
       "\n",
       "   sat18_total  act18_participation  act18_english  act18_math  act18_reading  \\\n",
       "0         1166                 1.00           18.9        18.3           19.6   \n",
       "1         1106                 0.33           19.8        20.6           21.6   \n",
       "2         1149                 0.66           18.2        19.4           19.5   \n",
       "3         1169                 1.00           19.1        18.9           19.7   \n",
       "4         1076                 0.27           22.5        22.5           23.0   \n",
       "\n",
       "   act18_science  act18_composite  \n",
       "0           19.0             19.1  \n",
       "1           20.7             20.8  \n",
       "2           19.2             19.2  \n",
       "3           19.4             19.4  \n",
       "4           22.1             22.7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satact_1718.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  states  sat17_participation\n",
       "15                  Iowa                 0.02\n",
       "24           Mississippi                 0.02\n",
       "34          North Dakota                 0.02\n",
       "6            Connecticut                 1.00\n",
       "7               Delaware                 1.00\n",
       "8   District of Columbia                 1.00\n",
       "22              Michigan                 1.00"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'sat17_participation' column\n",
    "min_sat17_par = satact_1718['sat17_participation']==satact_1718['sat17_participation'].min()\n",
    "max_sat17_par = satact_1718['sat17_participation']==satact_1718['sat17_participation'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest participation rates,\n",
    "# and then sorting the rows by participation rates in ascending order.\n",
    "minmax_sat17_par = satact_1718[['states', 'sat17_participation']].loc[(min_sat17_par) | (max_sat17_par)].sort_values(by='sat17_participation')\n",
    "minmax_sat17_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat18_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          states  sat18_participation\n",
       "34  North Dakota                 0.02\n",
       "5       Colorado                 1.00\n",
       "6    Connecticut                 1.00\n",
       "7       Delaware                 1.00\n",
       "12         Idaho                 1.00\n",
       "22      Michigan                 1.00"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'sat18_participation' column\n",
    "min_sat18_par = satact_1718['sat18_participation']==satact_1718['sat18_participation'].min()\n",
    "max_sat18_par = satact_1718['sat18_participation']==satact_1718['sat18_participation'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest participation rates,\n",
    "# and then sorting the rows by participation rates in ascending order.\n",
    "minmax_sat18_par = satact_1718[['states', 'sat18_participation']].loc[(min_sat18_par) | (max_sat18_par)].sort_values(by='sat18_participation')\n",
    "minmax_sat18_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_participation</th>\n",
       "      <th>sat18_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         states  sat17_participation  sat18_participation\n",
       "0  North Dakota                 0.02                 0.02\n",
       "1   Connecticut                 1.00                 1.00\n",
       "2      Delaware                 1.00                 1.00\n",
       "3      Michigan                 1.00                 1.00"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the above two dataframes on the 'states' column.\n",
    "# We use 'inner' join to filter only the states that appear in both the above two dataframes.\n",
    "\n",
    "sat1718_par_compare = pd.merge(minmax_sat17_par, minmax_sat18_par, on='states', how='inner')\n",
    "sat1718_par_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we observe the following:\n",
    "\n",
    "- **2017 SAT**\n",
    "    - **Lowest participation rates (2%) :** 3 states (Iowa, Mississippi and North Dakota)\n",
    "    - **Highest participation rates (100%) :** 4 states (Connecticut, Delaware, District of Columbia and Michigan)\n",
    "- **2018 SAT**\n",
    "    - **Lowest participation rates (2%) :** 1 state (North Dakota)\n",
    "    - **Highest participation rates (100%) :** 5 states (Colorado, Connecticut, Delaware, Idaho and Michigan)\n",
    "- North Dakota consistently has the lowest SAT participation rates of 2%.\n",
    "- Connecticut, Delaware and Michigan consistenly have the highest SAT participation rates of 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            states  act17_participation\n",
       "19           Maine                 0.08\n",
       "0          Alabama                 1.00\n",
       "44            Utah                 1.00\n",
       "42       Tennessee                 1.00\n",
       "40  South Carolina                 1.00\n",
       "36        Oklahoma                 1.00\n",
       "33  North Carolina                 1.00\n",
       "28          Nevada                 1.00\n",
       "26         Montana                 1.00\n",
       "25        Missouri                 1.00\n",
       "24     Mississippi                 1.00\n",
       "23       Minnesota                 1.00\n",
       "18       Louisiana                 1.00\n",
       "17        Kentucky                 1.00\n",
       "5         Colorado                 1.00\n",
       "3         Arkansas                 1.00\n",
       "49       Wisconsin                 1.00\n",
       "50         Wyoming                 1.00"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'act17_participation' column\n",
    "min_act17_par = satact_1718['act17_participation']==satact_1718['act17_participation'].min()\n",
    "max_act17_par = satact_1718['act17_participation']==satact_1718['act17_participation'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest participation rates,\n",
    "# and then sorting the rows by participation rates in ascending order.\n",
    "minmax_act17_par = satact_1718[['states', 'act17_participation']].loc[(min_act17_par) | (max_act17_par)].sort_values(by='act17_participation')\n",
    "minmax_act17_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act18_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            states  act18_participation\n",
       "19           Maine                 0.07\n",
       "0          Alabama                 1.00\n",
       "44            Utah                 1.00\n",
       "42       Tennessee                 1.00\n",
       "40  South Carolina                 1.00\n",
       "36        Oklahoma                 1.00\n",
       "35            Ohio                 1.00\n",
       "33  North Carolina                 1.00\n",
       "28          Nevada                 1.00\n",
       "27        Nebraska                 1.00\n",
       "26         Montana                 1.00\n",
       "25        Missouri                 1.00\n",
       "24     Mississippi                 1.00\n",
       "18       Louisiana                 1.00\n",
       "17        Kentucky                 1.00\n",
       "3         Arkansas                 1.00\n",
       "49       Wisconsin                 1.00\n",
       "50         Wyoming                 1.00"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'act18_participation' column\n",
    "min_act18_par = satact_1718['act18_participation']==satact_1718['act18_participation'].min()\n",
    "max_act18_par = satact_1718['act18_participation']==satact_1718['act18_participation'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest participation rates,\n",
    "# and then sorting the rows by participation rates in ascending order.\n",
    "minmax_act18_par = satact_1718[['states', 'act18_participation']].loc[(min_act18_par) | (max_act18_par)].sort_values(by='act18_participation')\n",
    "minmax_act18_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_participation</th>\n",
       "      <th>act18_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            states  act17_participation  act18_participation\n",
       "0            Maine                 0.08                 0.07\n",
       "1          Alabama                 1.00                 1.00\n",
       "2             Utah                 1.00                 1.00\n",
       "3        Tennessee                 1.00                 1.00\n",
       "4   South Carolina                 1.00                 1.00\n",
       "5         Oklahoma                 1.00                 1.00\n",
       "6   North Carolina                 1.00                 1.00\n",
       "7           Nevada                 1.00                 1.00\n",
       "8          Montana                 1.00                 1.00\n",
       "9         Missouri                 1.00                 1.00\n",
       "10     Mississippi                 1.00                 1.00\n",
       "11       Louisiana                 1.00                 1.00\n",
       "12        Kentucky                 1.00                 1.00\n",
       "13        Arkansas                 1.00                 1.00\n",
       "14       Wisconsin                 1.00                 1.00\n",
       "15         Wyoming                 1.00                 1.00"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the above two dataframes on the 'states' column.\n",
    "# We use 'inner' join to filter only the states that appear in both the above two dataframes.\n",
    "\n",
    "act1718_par_compare = pd.merge(minmax_act17_par, minmax_act18_par, on='states', how='inner')\n",
    "act1718_par_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we observe the following:\n",
    "\n",
    "- **2017 ACT**\n",
    "    - **Lowest participation rates:** 1 state (Maine)\n",
    "    - **Highest participation rates:** 17 states\n",
    "- **2018 ACT**\n",
    "    - **Lowest participation rates:** 1 state (Maine)\n",
    "    - **Highest participation rates:** 17 states\n",
    "- Maine consistently has the lowest ACT participation rates, and the rate drops from 8% (2017) to 7% (2018).\n",
    "- 15 states consistenly have the highest SAT participation rates of 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  states  sat17_total\n",
       "8   District of Columbia          950\n",
       "23             Minnesota         1295"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'sat17_total' column\n",
    "min_sat17_total = satact_1718['sat17_total']==satact_1718['sat17_total'].min()\n",
    "max_sat17_total = satact_1718['sat17_total']==satact_1718['sat17_total'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest average total scores,\n",
    "# and then sorting the rows by average total scores in ascending order.\n",
    "minmax_sat17_total = satact_1718[['states', 'sat17_total']].loc[(min_sat17_total) | (max_sat17_total)].sort_values(by='sat17_total')\n",
    "minmax_sat17_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat18_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  states  sat18_total\n",
       "8   District of Columbia          977\n",
       "23             Minnesota         1298"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'sat18_total' column\n",
    "min_sat18_total = satact_1718['sat18_total']==satact_1718['sat18_total'].min()\n",
    "max_sat18_total = satact_1718['sat18_total']==satact_1718['sat18_total'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest average total scores,\n",
    "# and then sorting the rows by average total scores in ascending order.\n",
    "minmax_sat18_total = satact_1718[['states', 'sat18_total']].loc[(min_sat18_total) | (max_sat18_total)].sort_values(by='sat18_total')\n",
    "minmax_sat18_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>sat17_total</th>\n",
       "      <th>sat18_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>950</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1295</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 states  sat17_total  sat18_total\n",
       "0  District of Columbia          950          977\n",
       "1             Minnesota         1295         1298"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat1718_total_compare = pd.merge(minmax_sat17_total, minmax_sat18_total, on='states', how='outer')\n",
    "sat1718_total_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we observe the following:\n",
    "\n",
    "- **2017 SAT**\n",
    "    - **Lowest average total score (950 / 1600) :** District of Columbia\n",
    "    - **Highest average total score (1295 / 1600) :** Minnesota\n",
    "- **2018 SAT**\n",
    "    - **Lowest average total score (977 / 1600) :** District of Columbia\n",
    "    - **Highest average total score (1298 / 1600) :** Minnesota\n",
    "- District of Columbia consistently has the lowest average total score.\n",
    "- Minnesota consistently has the highest average total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           states  act17_composite\n",
       "28         Nevada             17.8\n",
       "29  New Hampshire             25.5"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'act17_composite' column\n",
    "min_act17_composite = satact_1718['act17_composite']==satact_1718['act17_composite'].min()\n",
    "max_act17_composite = satact_1718['act17_composite']==satact_1718['act17_composite'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest average total scores,\n",
    "# and then sorting the rows by average total scores in ascending order.\n",
    "minmax_act17_composite = satact_1718[['states', 'act17_composite']].loc[(min_act17_composite) | (max_act17_composite)].sort_values(by='act17_composite')\n",
    "minmax_act17_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         states  act18_composite\n",
       "28       Nevada             17.7\n",
       "6   Connecticut             25.6"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating masks to obtain min & max values of 'act18_composite' column\n",
    "min_act18_composite = satact_1718['act18_composite']==satact_1718['act18_composite'].min()\n",
    "max_act18_composite = satact_1718['act18_composite']==satact_1718['act18_composite'].max()\n",
    "\n",
    "# Applying the masks to obtain states with the lowest OR highest average total scores,\n",
    "# and then sorting the rows by average total scores in ascending order.\n",
    "minmax_act18_composite = satact_1718[['states', 'act18_composite']].loc[(min_act18_composite) | (max_act18_composite)].sort_values(by='act18_composite')\n",
    "minmax_act18_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>act17_composite</th>\n",
       "      <th>act18_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>25.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          states  act17_composite  act18_composite\n",
       "0         Nevada             17.8             17.7\n",
       "1  New Hampshire             25.5              NaN\n",
       "2    Connecticut              NaN             25.6"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1718_comp_compare = pd.merge(minmax_act17_composite, minmax_act18_composite, on='states', how='outer')\n",
    "act1718_comp_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we observe the following:\n",
    "\n",
    "- **2017 ACT**\n",
    "    - **Lowest average composite score (17.8 / 36.0) :** Nevada\n",
    "    - **Highest average composite score (25.5 / 36.0) :** New Hampshire\n",
    "- **2018 ACT**\n",
    "    - **Lowest average composite score (17.7 / 36.0) :** Nevada\n",
    "    - **Highest average composite score (25.6 / 36.0) :** Connecticut\n",
    "- Nevada consistently has the lowest average composite score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Distributions in the data\n",
    "\n",
    "In this dataset, each data represents a sample from a population.                        \n",
    "For example, for ACT math test:\n",
    "- Population: the test results of all the students who take this test, nation-wide.\n",
    "- Population mean: is the national average of ACT math test (total scores/total no. of test takers) \n",
    "- Sample: the state means of ACT math test. We have 51 samples (51 states)\n",
    "\n",
    "***According to CLT, we generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores  - can we say students with higher SAT math score is better than those with lower ACT math score, or vice versa?\n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
