{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGE_CLASSIFICATION_OF_FACES_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf1Cx-7_VEyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Mount Google Drive (Optional) {display-mode: \"form\"}\n",
        "\n",
        "# Mount Google Drive if you want to access saved photos/videos to test in age classification below.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9UXRI0OVP9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Library Imports {display-mode: \"form\"}\n",
        "\n",
        "# Please refer to requirements.txt for a full list of all libraries and their versions used in this project.\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow    # cv.imshow() is known to crash Google Colab notebooks. This is the alternative suggested by Colab.\n",
        "import os\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7k3bhs1VnyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load Age Detection Model {display-mode: \"form\"}\n",
        "\n",
        "# Getting the trained CNN model from the source link.\n",
        "!wget -qq \"https://drive.google.com/uc?export=download&id=12MgZBpQ0N7suHnNecVMj_ae9zYqbjAhF\" -O \"age_detect_cnn_model.h5\"\n",
        "\n",
        "# Loading the trained CNN model for age classification, and defining a list of age-ranges as defined in the model.\n",
        "model = load_model(\"age_detect_cnn_model.h5\")\n",
        "age_ranges = ['1-2', '3-9', '10-20', '21-27', '28-45', '46-65', '66-116']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IMJrEh1QwW0",
        "colab_type": "text"
      },
      "source": [
        "**Face detection** in Python can be easily implemented using the ***OpenCV* library** (read about it [here](https://medium.com/analytics-vidhya/how-to-build-a-face-detection-model-in-python-8dc9cecadfe9)). In this notebook, I will be using the [Haar Cascades](https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html) classifier to detect faces. The pre-trained model file in XML format is already a part of the *OpenCV* package, or can be downloaded from [here](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kOsDMuoV_qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load Face Detection Model {display-mode: \"form\"}\n",
        "\n",
        "# Getting the trained CNN model from the source link.\n",
        "!wget -qq \"https://drive.google.com/uc?export=download&id=1Gcz4wc8iA1SHfV9REcK4i74Tf9vaETq7\" -O \"haarcascade_frontalface_default.xml\"\n",
        "\n",
        "# Importing the Haar Cascades classifier XML file.\n",
        "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPZEzuA81Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Define Necessary Functions {display-mode: \"form\"}\n",
        "\n",
        "# Defining a function to shrink the detected face region by a scale for better prediction in the model.\n",
        "\n",
        "def shrink_face_roi(x, y, w, h, scale=0.9):\n",
        "    wh_multiplier = (1-scale)/2\n",
        "    x_new = int(x + (w * wh_multiplier))\n",
        "    y_new = int(y + (h * wh_multiplier))\n",
        "    w_new = int(w * scale)\n",
        "    h_new = int(h * scale)\n",
        "    return (x_new, y_new, w_new, h_new)\n",
        "\n",
        "\n",
        "# Defining a function to create the predicted age overlay on the image by centering the text.\n",
        "\n",
        "def create_age_text(img, text, pct_text, x, y, w, h):\n",
        "\n",
        "    # Defining font, scales and thickness.\n",
        "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    text_scale = 1.2\n",
        "    yrsold_scale = 0.7\n",
        "    pct_text_scale = 0.65\n",
        "\n",
        "    # Getting width, height and baseline of age text and \"years old\".\n",
        "    (text_width, text_height), text_bsln = cv2.getTextSize(text, fontFace=fontFace, fontScale=text_scale, thickness=2)\n",
        "    (yrsold_width, yrsold_height), yrsold_bsln = cv2.getTextSize(\"years old\", fontFace=fontFace, fontScale=yrsold_scale, thickness=1)\n",
        "    (pct_text_width, pct_text_height), pct_text_bsln = cv2.getTextSize(pct_text, fontFace=fontFace, fontScale=pct_text_scale, thickness=1)\n",
        "\n",
        "    # Calculating center point coordinates of text background rectangle.\n",
        "    x_center = x + (w/2)\n",
        "    y_text_center = y + h + 20\n",
        "    y_yrsold_center = y + h + 48\n",
        "    y_pct_text_center = y + h + 75\n",
        "\n",
        "    # Calculating bottom left corner coordinates of text based on text size and center point of background rectangle calculated above.\n",
        "    x_text_org = int(round(x_center - (text_width / 2)))\n",
        "    y_text_org = int(round(y_text_center + (text_height / 2)))\n",
        "    x_yrsold_org = int(round(x_center - (yrsold_width / 2)))\n",
        "    y_yrsold_org = int(round(y_yrsold_center + (yrsold_height / 2)))\n",
        "    x_pct_text_org = int(round(x_center - (pct_text_width / 2)))\n",
        "    y_pct_text_org = int(round(y_pct_text_center + (pct_text_height / 2)))\n",
        "\n",
        "    face_age_background = cv2.rectangle(img, (x-1, y+h), (x+w+1, y+h+94), (0, 100, 0), cv2.FILLED)\n",
        "    face_age_text = cv2.putText(img, text, org=(x_text_org, y_text_org), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
        "    yrsold_text = cv2.putText(img, \"years old\", org=(x_yrsold_org, y_yrsold_org), fontFace=fontFace, fontScale=yrsold_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
        "    pct_age_text = cv2.putText(img, pct_text, org=(x_pct_text_org, y_pct_text_org), fontFace=fontFace, fontScale=pct_text_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
        "\n",
        "    return (face_age_background, face_age_text, yrsold_text)\n",
        "\n",
        "\n",
        "# Defining a function to find faces in an image and then classify each found face into age-ranges defined above.\n",
        "\n",
        "def classify_age(img):\n",
        "\n",
        "    # Making a copy of the image for overlay of ages and making a grayscale copy for passing to the loaded model for age classification.\n",
        "    img_copy = np.copy(img)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detecting faces in the image using the face_cascade loaded above and storing their coordinates into a list.\n",
        "    faces = face_cascade.detectMultiScale(img_copy, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
        "    # print(f\"{len(faces)} faces found.\")\n",
        "\n",
        "    # Looping through each face found in the image.\n",
        "    for i, (x, y, w, h) in enumerate(faces):\n",
        "\n",
        "        # Drawing a rectangle around the found face.\n",
        "        face_rect = cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 100, 0), thickness=2)\n",
        "        \n",
        "        # Predicting the age of the found face using the model loaded above.\n",
        "        x2, y2, w2, h2 = shrink_face_roi(x, y, w, h)\n",
        "        face_roi = img_gray[y2:y2+h2, x2:x2+w2]\n",
        "        face_roi = cv2.resize(face_roi, (200, 200))\n",
        "        face_roi = face_roi.reshape(-1, 200, 200, 1)\n",
        "        face_age = age_ranges[np.argmax(model.predict(face_roi))]\n",
        "        face_age_pct = f\"({round(np.max(model.predict(face_roi))*100, 2)}%)\"\n",
        "        \n",
        "        # Calling the above defined function to create the predicted age overlay on the image.\n",
        "        face_age_background, face_age_text, yrsold_text = create_age_text(img_copy, face_age, face_age_pct, x, y, w, h)\n",
        "        # print(f\"Age prediction for face {i+1} : {face_age} years old\")\n",
        "\n",
        "    return img_copy\n",
        "\n",
        "\n",
        "# Defining a function to return the image filepath with a new filename.\n",
        "# If INPUT filepath is \"my_folder1/my_folder2/my_image.jpg\", OUTPUT filepath will be \"my_folder1/my_folder2/my_image_WITH_AGE.jpg\"\n",
        "\n",
        "def new_img_name(org_img_path):\n",
        "    img_path, img_name_ext = os.path.split(org_img_path)\n",
        "    img_name, img_ext = os.path.splitext(img_name_ext)\n",
        "\n",
        "    new_img_name_ext = img_name+\"_WITH_AGE\"+img_ext\n",
        "    new_img_path = os.path.join(img_path, new_img_name_ext)\n",
        "\n",
        "    return new_img_path\n",
        "\n",
        "\n",
        "# Defining a function to return the video filepath with a new filename.\n",
        "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
        "\n",
        "def new_vid_name(org_vid_path):\n",
        "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
        "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
        "\n",
        "    new_vid_name_ext = vid_name+\"_WITH_AGE\"+\".mp4\"\n",
        "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
        "\n",
        "    return new_vid_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5xEOUibhtro",
        "colab_type": "text"
      },
      "source": [
        "# Age Detection on Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icovpC8xoovn",
        "colab_type": "text"
      },
      "source": [
        "To detect age on an image, either:\n",
        "1. use **Capture Webcam Image** code cell below to take a picture using your webcam *(browser may ask for permission to access the webcam)*, or\n",
        "2. **upload your own image** using the *Files* &#10141; *Upload to session storage* button in the left panel and **provide the image filename in the cell below**, or\n",
        "3. **mount your Google Drive** by running the cell at the beginning of this notebook and **provide the filepath to the image in the cell below**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvkMTD-TcKkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Capture Webcam Image {display-mode: \"form\"}\n",
        "\n",
        "# Webcam image capture\n",
        "# Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='my_photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked.\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "\n",
        "from IPython.display import Image\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print('Saved to {}'.format(filename))\n",
        "  \n",
        "    # Show the image which was just taken.\n",
        "    display(Image(filename))\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4VRsPUITtGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provide the image filepath as a string below.\n",
        "# For example: \"my_image.jpg\" or \"/content/drive/My Drive/my_folder/my_image.png\"\n",
        "\n",
        "my_image = \"my_photo.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2hslI-PwcGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run Age Detection on Image {display-mode: \"form\"}\n",
        "\n",
        "# Reading the image from filepath provided above and passing it through the age clasification method defined above.\n",
        "\n",
        "img = cv2.imread(my_image)\n",
        "age_img = classify_age(img)\n",
        "\n",
        "# Saving the new generated image with a new name at the same location. \n",
        "try:\n",
        "    new_my_image = new_img_name(my_image)\n",
        "    cv2.imwrite(new_my_image, age_img)\n",
        "    print(f\"Saved to {new_my_image}\")\n",
        "except:\n",
        "    print(\"Error: Could not save image!\")\n",
        "\n",
        "cv2_imshow(age_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yrMHUwXhQSy",
        "colab_type": "text"
      },
      "source": [
        "# Age Detection on Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ghqzfehRNe",
        "colab_type": "text"
      },
      "source": [
        "To detect age on a video, either:\n",
        "1. **upload your own video** using the \"*Files* &#10141; *Upload to session storage*\" button in the left panel and **provide the video filename in the cell below**, or\n",
        "3. **mount your Google Drive** by running the cell at the beginning of this notebook and **provide the filepath to the video in the cell below**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifcaQnP_EfJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provide the video filepath as a string below\n",
        "# For example: \"my_video.mp4\" or \"/content/drive/My Drive/my_folder/my_video.mp4\"\n",
        "\n",
        "my_video = \"my_video.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWruhEEcKji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run Age Detection on Video {display-mode: \"form\"}\n",
        "\n",
        "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
        "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
        "\n",
        "# Creating a VideoCapture object.\n",
        "cap = cv2.VideoCapture(my_video)\n",
        "\n",
        "# Getting the video frame width and height.\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "new_my_video = new_vid_name(my_video)\n",
        "out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    \n",
        "    # Grabbing each individual frame, frame-by-frame.\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if ret==True:\n",
        "        \n",
        "        # Running age detection on the grabbed frame.\n",
        "        age_img = classify_age(frame)\n",
        "        \n",
        "        # Saving frame to output video using the VideoWriter object defined above.\n",
        "        out.write(age_img)\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Releasing the VideoCapture and VideoWriter objects.\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Saved to {new_my_video}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZTmucIVCx6W",
        "colab_type": "text"
      },
      "source": [
        "To run age detection on a **live webcam video**, download the ZIP folder from [here](https://drive.google.com/file/d/18eG9nXqmlCHLp_DkFg-d0IReh34Kr3AG/view?usp=sharing) and run the notebook ***AGE_CLASSIFICATION_OF_FACES_offline.ipynb*** locally on your machine."
      ]
    }
  ]
}